{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal- To re-scrape the data into sql database. \n",
    "\n",
    "The goal her is to re-srape the database. I noted that not all of the files were put into into the data base.\n",
    "\n",
    "### Import modules:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modules\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'   #this makes it retina style (oh yeah!)\n",
    "from bs4 import BeautifulSoup\n",
    "from os.path import join\n",
    "from pandas import DataFrame\n",
    "from os import getcwd, listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#append the path for my own funtions and import them \n",
    "import sys\n",
    "sys.path.append('/home/ubuntu/InsightProject')\n",
    "from scraper import * \n",
    "from data_functions import *\n",
    "\n",
    "\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "from validators.url import url as validate_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy import Column, Table, MetaData,create_engine\n",
    "from sqlalchemy.dialects.mysql import *\n",
    "from sqlalchemy.sql.expression import insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/data/html'\n",
    "htmls = listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of total files is 53054. The number of unique files is 53054.\n"
     ]
    }
   ],
   "source": [
    "print 'The number of total files is %d. The number of unique files is %d.' %(len(htmls), len(np.unique(htmls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the connection to the database\n",
    "\n",
    "1. Connect an engine to the database.\n",
    "2. Create a metadata object and bind it to the data. \n",
    "3. Create an table object representing the table of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creat an engine with 32 connections\n",
    "eng = create_engine('mysql://root:what@localhost/url',pool_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('information_schema',), ('mysql',), ('performance_schema',), ('url',)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng.execute('show databases').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta = MetaData()\n",
    "meta.bind = eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_htmls = Table('classifier_htmls',meta,\n",
    "            Column('urlID', INTEGER, primary_key=True, autoincrement=True),\n",
    "            Column('url', VARCHAR(60)),\n",
    "            Column('htmlsText',MEDIUMTEXT),\n",
    "            Column('htmlsSize', INTEGER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_text(html):\n",
    "    \"\"\" parses the html and inserts into the database\"\"\"\n",
    "    \n",
    "    # parste the text and calculate the size\n",
    "    html_path = '/home/ubuntu/data/html'\n",
    "    url = html   #get the urginal url\n",
    "    html = join(html_path, html)\n",
    "    parsed = scrape_all_text(html)\n",
    "    size = len(parsed)\n",
    "    \n",
    "    # handle the insertion into the table. \n",
    "    eng.dispose()\n",
    "    with eng.connect() as conn:\n",
    "        # insert the data into the database. \n",
    "        ins = classifier_htmls.insert().values(url = url, htmlsText = parsed, htmlsSize=size)\n",
    "        conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert_htmls(htmls,threads = 32):\n",
    "    \"\"\"inserts into the database\"\"\"\n",
    "    pool = Pool(threads)\n",
    "    pool.map(parse_text, htmls)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```insert_htmls(htmls)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_sql('select * from classifier_htmls', con = eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52499"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to redo this scraping. It sucked. Note that it did not parse everything. But this is a large enough data set for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### do the students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "student_htmls = Table('student_htmls',meta,\n",
    "            Column('urlID', INTEGER, primary_key=True, autoincrement=True),\n",
    "            Column('url', VARCHAR(60)),\n",
    "            Column('htmlsText',MEDIUMTEXT),\n",
    "            Column('htmlsSize', INTEGER))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_student_text(html):\n",
    "    \"\"\" parses the html and inserts into the database\"\"\"\n",
    "    \n",
    "    # parste the text and calculate the size\n",
    "    html_path = '/home/ubuntu/data/student_html'\n",
    "    url = html   #get the urginal url\n",
    "    html = join(html_path, html)\n",
    "    parsed = scrape_all_text(html)\n",
    "    size = len(parsed)\n",
    "    \n",
    "    # handle the insertion into the table. \n",
    "    eng.dispose()\n",
    "    with eng.connect() as conn:\n",
    "        # insert the data into the database. \n",
    "        ins = student_htmls.insert().values(url = url, htmlsText = parsed, htmlsSize=size)\n",
    "        conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_student_htmls(htmls,threads = 32):\n",
    "    \"\"\"inserts into the database\"\"\"\n",
    "    pool = Pool(threads)\n",
    "    pool.map(parse_student_text, htmls)\n",
    "    pool.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
